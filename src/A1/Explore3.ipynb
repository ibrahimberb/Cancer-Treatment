{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 642844190171084316\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4163895296\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15476079312374875216\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# check if tensorflow uses GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_variants_df = pd.read_csv(\"../../data/training_variants/training_variants\")\n",
    "train_txt_df = pd.read_csv(\"../../data/training_text/training_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "train_data = pd.merge(train_variants_df, train_txt_df, on='ID')\n",
    "\n",
    "# get rid of NaN entries in Text column\n",
    "train_data = train_data[train_data['Text'].notnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   ID    Gene             Variation  Class  \\\n0   0  FAM58A  Truncating Mutations      1   \n1   1     CBL                 W802*      2   \n2   2     CBL                 Q249E      2   \n3   3     CBL                 N454D      3   \n4   4     CBL                 L399V      4   \n\n                                                Text  \n0  Cyclin-dependent kinases (CDKs) regulate a var...  \n1   Abstract Background  Non-small cell lung canc...  \n2   Abstract Background  Non-small cell lung canc...  \n3  Recent evidence has demonstrated that acquired...  \n4  Oncogenic mutations in the monomeric Casitas B...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Gene</th>\n      <th>Variation</th>\n      <th>Class</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>FAM58A</td>\n      <td>Truncating Mutations</td>\n      <td>1</td>\n      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>CBL</td>\n      <td>W802*</td>\n      <td>2</td>\n      <td>Abstract Background  Non-small cell lung canc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>CBL</td>\n      <td>Q249E</td>\n      <td>2</td>\n      <td>Abstract Background  Non-small cell lung canc...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>CBL</td>\n      <td>N454D</td>\n      <td>3</td>\n      <td>Recent evidence has demonstrated that acquired...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>CBL</td>\n      <td>L399V</td>\n      <td>4</td>\n      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [6], line 32\u001B[0m\n\u001B[0;32m     29\u001B[0m train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mText\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mText\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: clean_text(x))\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# create a function to remove stopwords\u001B[39;00m\n\u001B[1;32m---> 32\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\n\u001B[0;32m     34\u001B[0m nltk\u001B[38;5;241m.\u001B[39mdownload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstopwords\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     35\u001B[0m nltk\u001B[38;5;241m.\u001B[39mdownload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpunkt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# create an LSTM model to predict the class of a given text\n",
    "\n",
    "# import libraries  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "\n",
    "print(\"Cleaning text...\")\n",
    "\n",
    "# create a function to clean the text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>+', '', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "# clean the text\n",
    "train_data['Text'] = train_data['Text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# create a function to remove stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "# remove stopwords\n",
    "train_data['Text'] = train_data['Text'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# create a function to lemmatize the text\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "    return \" \".join(lemmatized_text)\n",
    "\n",
    "# lemmatize the text    \n",
    "train_data['Text'] = train_data['Text'].apply(lambda x: lemmatize_text(x))\n",
    "\n",
    "# create a function to stem the text\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stemmed_text = [stemmer.stem(word) for word in word_tokens]\n",
    "    return \" \".join(stemmed_text)\n",
    "\n",
    "# stem the text\n",
    "train_data['Text'] = train_data['Text'].apply(lambda x: stem_text(x))\n",
    "\n",
    "# create a function to remove punctuation\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    no_punct_text = [word for word in word_tokens if word not in string.punctuation]\n",
    "    return \" \".join(no_punct_text)\n",
    "\n",
    "# remove punctuation\n",
    "train_data['Text'] = train_data['Text'].apply(lambda x: remove_punctuation(x))\n",
    "\n",
    "# create a function to remove numbers\n",
    "import re\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "\n",
    "# remove numbers\n",
    "train_data['Text'] = train_data['Text'].apply(lambda x: remove_numbers(x))\n",
    "\n",
    "\n",
    "print(\"Creating tokenizer...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          64000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               98816     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "import os\n",
    "\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "model.add(keras.layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(keras.layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model.add(keras.layers.Dense(10))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_1/Cast' defined at (most recent call last):\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\asyncio\\base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_14636\\3652420372.py\", line 2, in <module>\n      predictions = model.predict(train_data['Text'])\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\functional.py\", line 578, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\functional.py\", line 678, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential_1/Cast'\nCast string to float is not supported\n\t [[{{node sequential_1/Cast}}]] [Op:__inference_predict_function_1035]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnimplementedError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [10], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[39m# predict on the same data\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m predictions \u001B[39m=\u001B[39m model\u001B[39m.\u001B[39;49mpredict(train_data[\u001B[39m'\u001B[39;49m\u001B[39mText\u001B[39;49m\u001B[39m'\u001B[39;49m])\n\u001B[0;32m      3\u001B[0m predictions\n",
      "File \u001B[1;32mc:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[39mexcept\u001B[39;00m \u001B[39mException\u001B[39;00m \u001B[39mas\u001B[39;00m e:  \u001B[39m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[39m=\u001B[39m _process_traceback_frames(e\u001B[39m.\u001B[39m__traceback__)\n\u001B[1;32m---> 67\u001B[0m   \u001B[39mraise\u001B[39;00m e\u001B[39m.\u001B[39mwith_traceback(filtered_tb) \u001B[39mfrom\u001B[39;00m \u001B[39mNone\u001B[39m\n\u001B[0;32m     68\u001B[0m \u001B[39mfinally\u001B[39;00m:\n\u001B[0;32m     69\u001B[0m   \u001B[39mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mc:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[39m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[39m=\u001B[39m pywrap_tfe\u001B[39m.\u001B[39mTFE_Py_Execute(ctx\u001B[39m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[39mexcept\u001B[39;00m core\u001B[39m.\u001B[39m_NotOkStatusException \u001B[39mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[39mif\u001B[39;00m name \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n",
      "\u001B[1;31mUnimplementedError\u001B[0m: Graph execution error:\n\nDetected at node 'sequential_1/Cast' defined at (most recent call last):\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\asyncio\\base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_14636\\3652420372.py\", line 2, in <module>\n      predictions = model.predict(train_data['Text'])\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\functional.py\", line 578, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"c:\\Users\\ibrah\\anaconda3\\envs\\CSDS458_Bio\\lib\\site-packages\\keras\\engine\\functional.py\", line 678, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential_1/Cast'\nCast string to float is not supported\n\t [[{{node sequential_1/Cast}}]] [Op:__inference_predict_function_1035]"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "import os\n",
    "\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('CSDS458_Bio')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7310b0c834e61f1bcbffb34dc8ba90cec34b48e435c4d3cc381c12e268b09379"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
